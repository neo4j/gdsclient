{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "aura"
    ]
   },
   "source": [
    "# GDS Sessions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/neo4j/graph-data-science-client/blob/main/examples/gds-sessions.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Jupyter notebook is hosted [here](https://github.com/neo4j/graph-data-science-client/blob/main/examples/gds-sessions.ipynb) in the Neo4j Graph Data Science Client Github repository.\n",
    "\n",
    "The notebook shows how to use the `graphdatascience` Python library to create, manage, and use a GDS Session.\n",
    "\n",
    "We consider a graph of people and fruits, which we're using as a simple example to show how to connect your AuraDB instance to a GDS Session, run algorithms, and eventually write back your analytical results to the AuraDB database. \n",
    "We will cover all management operations: creation, listing, and deletion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "This notebook requires having an AuraDB instance available.\n",
    "We also need to have the `graphdatascience` Python library installed, version `1.11a3` or later.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "verify-version"
    ]
   },
   "outputs": [],
   "source": [
    "%pip install --pre \"graphdatascience>1.10\""
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-12T15:42:12.159786Z",
     "start_time": "2024-07-12T15:42:12.155900Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(\"credentials.env\")"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 29
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-12T15:42:29.582497Z",
     "start_time": "2024-07-12T15:42:25.111372Z"
    }
   },
   "source": [
    "from datetime import datetime\n",
    "import os\n",
    "from graphdatascience.session import GdsSessions, AuraAPICredentials, SessionMemory\n",
    "from graphdatascience.session import DbmsConnectionInfo\n",
    "\n",
    "client_id = os.environ[\"AURA_API_CLIENT_ID\"]\n",
    "client_secret = os.environ[\"AURA_API_CLIENT_SECRET\"]\n",
    "\n",
    "\n",
    "def log(msg: str):\n",
    "    current_datetime = datetime.now()\n",
    "    print(f\"{current_datetime}\\t{msg}\")\n",
    "\n",
    "\n",
    "# If your account is a member of several tenants, you must also specify the tenant ID to use\n",
    "sessions = GdsSessions(api_credentials=AuraAPICredentials(client_id, client_secret, tenant=os.environ[\"TENANT\"]))\n",
    "\n",
    "\n",
    "connection_info = DbmsConnectionInfo(\"neo4j+s://ad6df740-staging.databases.neo4j.io\", \"neo4j\", \"5VVYRocCOuwvd5W9rKp6Y51g2Scou9cpzgGrnbWSyko\")\n",
    "\n",
    "session_name = f\"e2e-test-gcp\"\n",
    "\n",
    "log(f\"Creating GDS session on instance 'mats-test' with name `{session_name}`.\")\n",
    "gds = sessions.get_or_create(session_name, SessionMemory.m_32GB, connection_info)\n",
    "\n",
    "\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-12 17:42:25.113954\tCreating GDS session on instance 'mats-test' with name `e2e-test-gcp`.\n"
     ]
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-12T10:01:20.625025Z",
     "start_time": "2024-07-12T09:58:39.960372Z"
    }
   },
   "cell_type": "code",
   "source": [
    "log(\"Running remote projection.\")\n",
    "G, _ = gds.graph.project(\"g\", \"\"\"\n",
    "    CYPHER runtime=parallel\n",
    "    MATCH (n)-[r]->(m)\n",
    "    WITH gds.graph.project.remote(n, m, {\n",
    "        targetNodeLabels: labels(m),\n",
    "        relationshipType: type(r)\n",
    "    }) as g\n",
    "    RETURN g\n",
    "    \"\"\"\n",
    ")\n",
    "log(\"Projection complete.\")\n",
    "\n",
    "\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-12 11:58:39.961203\tRunning remote projection.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to read from defunct connection IPv4Address(('ad6df740-c872c364-gds.staging-orch-0001.neo4j.io', 7687)) (ResolvedIPv4Address(('35.195.103.236', 7687)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-12 12:01:19.994768\tProjection complete.\n",
      "2024-07-12 12:01:19.994938\tRunning connected components.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to read from defunct connection ResolvedIPv4Address(('35.195.103.236', 7687)) (ResolvedIPv4Address(('35.195.103.236', 7687)))\n",
      "Unable to retrieve routing information\n"
     ]
    },
    {
     "ename": "ServiceUnavailable",
     "evalue": "Unable to retrieve routing information",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mServiceUnavailable\u001B[0m                        Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[8], line 16\u001B[0m\n\u001B[1;32m     13\u001B[0m log(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mProjection complete.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     15\u001B[0m log(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mRunning connected components.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m---> 16\u001B[0m gds\u001B[38;5;241m.\u001B[39mwcc\u001B[38;5;241m.\u001B[39mmutate(G, mutateProperty\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcomponentId\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     17\u001B[0m log(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mConnected components complete.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/gitRoots/graph-data-science-client/graphdatascience/algo/algo_proc_runner.py:33\u001B[0m, in \u001B[0;36mStandardModeRunner.__call__\u001B[0;34m(self, G, **config)\u001B[0m\n\u001B[1;32m     32\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, G: Graph, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mconfig: Any) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mSeries[Any]\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m---> 33\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_run_procedure(G, config)\u001B[38;5;241m.\u001B[39msqueeze()\n",
      "File \u001B[0;32m~/gitRoots/graph-data-science-client/graphdatascience/graph/graph_type_check.py:18\u001B[0m, in \u001B[0;36mgraph_type_check.<locals>.wrapper\u001B[0;34m(self, G, *args, **kwargs)\u001B[0m\n\u001B[1;32m     12\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(G, \u001B[38;5;28mstr\u001B[39m):\n\u001B[1;32m     13\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\n\u001B[1;32m     14\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThe parameter \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mG\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m takes a `Graph` object, but received string \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mG\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     15\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTo resolve a graph name string into a `Graph` object, please use `gds.graph.get`\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     16\u001B[0m     )\n\u001B[0;32m---> 18\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;28mself\u001B[39m, G, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m~/gitRoots/graph-data-science-client/graphdatascience/algo/algo_proc_runner.py:18\u001B[0m, in \u001B[0;36mAlgoProcRunner._run_procedure\u001B[0;34m(self, G, config, with_logging)\u001B[0m\n\u001B[1;32m     14\u001B[0m \u001B[38;5;129m@graph_type_check\u001B[39m\n\u001B[1;32m     15\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_run_procedure\u001B[39m(\u001B[38;5;28mself\u001B[39m, G: Graph, config: Dict[\u001B[38;5;28mstr\u001B[39m, Any], with_logging: \u001B[38;5;28mbool\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m DataFrame:\n\u001B[1;32m     16\u001B[0m     params \u001B[38;5;241m=\u001B[39m CallParameters(graph_name\u001B[38;5;241m=\u001B[39mG\u001B[38;5;241m.\u001B[39mname(), config\u001B[38;5;241m=\u001B[39mconfig)\n\u001B[0;32m---> 18\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_query_runner\u001B[38;5;241m.\u001B[39mcall_procedure(endpoint\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_namespace, params\u001B[38;5;241m=\u001B[39mparams, logging\u001B[38;5;241m=\u001B[39mwith_logging)\n",
      "File \u001B[0;32m~/gitRoots/graph-data-science-client/graphdatascience/query_runner/aura_db_query_runner.py:56\u001B[0m, in \u001B[0;36mAuraDbQueryRunner.call_procedure\u001B[0;34m(self, endpoint, params, yields, database, logging, custom_error)\u001B[0m\n\u001B[1;32m     53\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m.write\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m endpoint \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mis_remote_projected_graph(params[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mgraph_name\u001B[39m\u001B[38;5;124m\"\u001B[39m]):\n\u001B[1;32m     54\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_remote_write_back(endpoint, params, yields, database, logging, custom_error)\n\u001B[0;32m---> 56\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_gds_query_runner\u001B[38;5;241m.\u001B[39mcall_procedure(endpoint, params, yields, database, logging, custom_error)\n",
      "File \u001B[0;32m~/gitRoots/graph-data-science-client/graphdatascience/query_runner/arrow_query_runner.py:200\u001B[0m, in \u001B[0;36mArrowQueryRunner.call_procedure\u001B[0;34m(self, endpoint, params, yields, database, logging, custom_error)\u001B[0m\n\u001B[1;32m    191\u001B[0m                 \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mwarn_about_deprecation(\n\u001B[1;32m    192\u001B[0m                     old_endpoint\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mgds.beta.graph.relationships.stream\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    193\u001B[0m                     new_endpoint\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mgds.graph.relationships.stream\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    194\u001B[0m                 )\n\u001B[1;32m    196\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_gds_arrow_client\u001B[38;5;241m.\u001B[39mget_property(\n\u001B[1;32m    197\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdatabase(), graph_name, endpoint, {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrelationship_types\u001B[39m\u001B[38;5;124m\"\u001B[39m: relationship_types}\n\u001B[1;32m    198\u001B[0m     )\n\u001B[0;32m--> 200\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_fallback_query_runner\u001B[38;5;241m.\u001B[39mcall_procedure(endpoint, params, yields, database, logging, custom_error)\n",
      "File \u001B[0;32m~/gitRoots/graph-data-science-client/graphdatascience/query_runner/neo4j_query_runner.py:150\u001B[0m, in \u001B[0;36mNeo4jQueryRunner.call_procedure\u001B[0;34m(self, endpoint, params, yields, database, logging, custom_error)\u001B[0m\n\u001B[1;32m    147\u001B[0m query \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCALL \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mendpoint\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m(\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mparams\u001B[38;5;241m.\u001B[39mplaceholder_str()\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m)\u001B[39m\u001B[38;5;132;01m{\u001B[39;00myields_clause\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    149\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m logging:\n\u001B[0;32m--> 150\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrun_cypher_with_logging(query, params, database)\n\u001B[1;32m    151\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    152\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrun_cypher(query, params, database, custom_error)\n",
      "File \u001B[0;32m~/gitRoots/graph-data-science-client/graphdatascience/query_runner/neo4j_query_runner.py:179\u001B[0m, in \u001B[0;36mNeo4jQueryRunner.run_cypher_with_logging\u001B[0;34m(self, query, params, database)\u001B[0m\n\u001B[1;32m    176\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_log(job_id, future, database)\n\u001B[1;32m    178\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m future\u001B[38;5;241m.\u001B[39mexception():\n\u001B[0;32m--> 179\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m future\u001B[38;5;241m.\u001B[39mexception()  \u001B[38;5;66;03m# type: ignore\u001B[39;00m\n\u001B[1;32m    180\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    181\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m future\u001B[38;5;241m.\u001B[39mresult()\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/py311/lib/python3.11/concurrent/futures/thread.py:58\u001B[0m, in \u001B[0;36m_WorkItem.run\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m     55\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m\n\u001B[1;32m     57\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 58\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfn(\u001B[38;5;241m*\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mkwargs)\n\u001B[1;32m     59\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mBaseException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m exc:\n\u001B[1;32m     60\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfuture\u001B[38;5;241m.\u001B[39mset_exception(exc)\n",
      "File \u001B[0;32m~/gitRoots/graph-data-science-client/graphdatascience/query_runner/neo4j_query_runner.py:109\u001B[0m, in \u001B[0;36mNeo4jQueryRunner.run_cypher\u001B[0;34m(self, query, params, database, custom_error)\u001B[0m\n\u001B[1;32m    107\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    108\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m custom_error:\n\u001B[0;32m--> 109\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandle_driver_exception(session, e)\n\u001B[1;32m    110\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    111\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m e\n",
      "File \u001B[0;32m~/gitRoots/graph-data-science-client/graphdatascience/query_runner/neo4j_query_runner.py:306\u001B[0m, in \u001B[0;36mNeo4jQueryRunner.handle_driver_exception\u001B[0;34m(session, e)\u001B[0m\n\u001B[1;32m    301\u001B[0m reg_gds_hit \u001B[38;5;241m=\u001B[39m re\u001B[38;5;241m.\u001B[39msearch(\n\u001B[1;32m    302\u001B[0m     \u001B[38;5;124mr\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThere is no procedure with the name `(gds(?:\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mw+)+)` registered for this database instance\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    303\u001B[0m     \u001B[38;5;28mstr\u001B[39m(e),\n\u001B[1;32m    304\u001B[0m )\n\u001B[1;32m    305\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m reg_gds_hit:\n\u001B[0;32m--> 306\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\n\u001B[1;32m    308\u001B[0m requested_endpoint \u001B[38;5;241m=\u001B[39m reg_gds_hit\u001B[38;5;241m.\u001B[39mgroup(\u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m    310\u001B[0m list_result \u001B[38;5;241m=\u001B[39m session\u001B[38;5;241m.\u001B[39mrun(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCALL gds.list() YIELD name\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/gitRoots/graph-data-science-client/graphdatascience/query_runner/neo4j_query_runner.py:106\u001B[0m, in \u001B[0;36mNeo4jQueryRunner.run_cypher\u001B[0;34m(self, query, params, database, custom_error)\u001B[0m\n\u001B[1;32m    104\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_driver\u001B[38;5;241m.\u001B[39msession(database\u001B[38;5;241m=\u001B[39mdatabase, bookmarks\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbookmarks()) \u001B[38;5;28;01mas\u001B[39;00m session:\n\u001B[1;32m    105\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 106\u001B[0m         result \u001B[38;5;241m=\u001B[39m session\u001B[38;5;241m.\u001B[39mrun(query, params)\n\u001B[1;32m    107\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    108\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m custom_error:\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/py311/lib/python3.11/site-packages/neo4j/_sync/work/session.py:302\u001B[0m, in \u001B[0;36mSession.run\u001B[0;34m(self, query, parameters, **kwargs)\u001B[0m\n\u001B[1;32m    299\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_auto_result\u001B[38;5;241m.\u001B[39m_buffer_all()\n\u001B[1;32m    301\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_connection:\n\u001B[0;32m--> 302\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_connect(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_config\u001B[38;5;241m.\u001B[39mdefault_access_mode)\n\u001B[1;32m    303\u001B[0m     \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_connection \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    304\u001B[0m cx \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_connection\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/py311/lib/python3.11/site-packages/neo4j/_sync/work/session.py:130\u001B[0m, in \u001B[0;36mSession._connect\u001B[0;34m(self, access_mode, **acquire_kwargs)\u001B[0m\n\u001B[1;32m    128\u001B[0m     access_mode \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_config\u001B[38;5;241m.\u001B[39mdefault_access_mode\n\u001B[1;32m    129\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 130\u001B[0m     \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39m_connect(\n\u001B[1;32m    131\u001B[0m         access_mode, auth\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_config\u001B[38;5;241m.\u001B[39mauth, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39macquire_kwargs\n\u001B[1;32m    132\u001B[0m     )\n\u001B[1;32m    133\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m asyncio\u001B[38;5;241m.\u001B[39mCancelledError:\n\u001B[1;32m    134\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_handle_cancellation(message\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_connect\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/py311/lib/python3.11/site-packages/neo4j/_sync/work/workspace.py:182\u001B[0m, in \u001B[0;36mWorkspace._connect\u001B[0;34m(self, access_mode, auth, **acquire_kwargs)\u001B[0m\n\u001B[1;32m    173\u001B[0m acquire_kwargs_ \u001B[38;5;241m=\u001B[39m {\n\u001B[1;32m    174\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124maccess_mode\u001B[39m\u001B[38;5;124m\"\u001B[39m: access_mode,\n\u001B[1;32m    175\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtimeout\u001B[39m\u001B[38;5;124m\"\u001B[39m: acquisition_timeout,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    179\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mliveness_check_timeout\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m    180\u001B[0m }\n\u001B[1;32m    181\u001B[0m acquire_kwargs_\u001B[38;5;241m.\u001B[39mupdate(acquire_kwargs)\n\u001B[0;32m--> 182\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_connection \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pool\u001B[38;5;241m.\u001B[39macquire(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39macquire_kwargs_)\n\u001B[1;32m    183\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_connection_access_mode \u001B[38;5;241m=\u001B[39m access_mode\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/py311/lib/python3.11/site-packages/neo4j/_sync/io/_pool.py:910\u001B[0m, in \u001B[0;36mNeo4jPool.acquire\u001B[0;34m(self, access_mode, timeout, database, bookmarks, auth, liveness_check_timeout)\u001B[0m\n\u001B[1;32m    903\u001B[0m \u001B[38;5;66;03m#     await self.ensure_routing_table_is_fresh(\u001B[39;00m\n\u001B[1;32m    904\u001B[0m \u001B[38;5;66;03m#         access_mode=access_mode, database=database, imp_user=None,\u001B[39;00m\n\u001B[1;32m    905\u001B[0m \u001B[38;5;66;03m#         bookmarks=bookmarks, acquisition_timeout=timeout\u001B[39;00m\n\u001B[1;32m    906\u001B[0m \u001B[38;5;66;03m#     )\u001B[39;00m\n\u001B[1;32m    908\u001B[0m log\u001B[38;5;241m.\u001B[39mdebug(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m[#0000]  _: <POOL> acquire routing connection, \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    909\u001B[0m           \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124maccess_mode=\u001B[39m\u001B[38;5;132;01m%r\u001B[39;00m\u001B[38;5;124m, database=\u001B[39m\u001B[38;5;132;01m%r\u001B[39;00m\u001B[38;5;124m\"\u001B[39m, access_mode, database)\n\u001B[0;32m--> 910\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mensure_routing_table_is_fresh(\n\u001B[1;32m    911\u001B[0m     access_mode\u001B[38;5;241m=\u001B[39maccess_mode, database\u001B[38;5;241m=\u001B[39mdatabase,\n\u001B[1;32m    912\u001B[0m     imp_user\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, bookmarks\u001B[38;5;241m=\u001B[39mbookmarks, auth\u001B[38;5;241m=\u001B[39mauth,\n\u001B[1;32m    913\u001B[0m     acquisition_timeout\u001B[38;5;241m=\u001B[39mtimeout\n\u001B[1;32m    914\u001B[0m )\n\u001B[1;32m    916\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[1;32m    917\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    918\u001B[0m         \u001B[38;5;66;03m# Get an address for a connection that have the fewest in-use\u001B[39;00m\n\u001B[1;32m    919\u001B[0m         \u001B[38;5;66;03m# connections.\u001B[39;00m\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/py311/lib/python3.11/site-packages/neo4j/_sync/io/_pool.py:852\u001B[0m, in \u001B[0;36mNeo4jPool.ensure_routing_table_is_fresh\u001B[0;34m(self, access_mode, database, imp_user, bookmarks, auth, acquisition_timeout, database_callback)\u001B[0m\n\u001B[1;32m    848\u001B[0m     log\u001B[38;5;241m.\u001B[39mdebug(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m[#0000]  _: <POOL> using existing routing table \u001B[39m\u001B[38;5;132;01m%r\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    849\u001B[0m               routing_table)\n\u001B[1;32m    850\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[0;32m--> 852\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mupdate_routing_table(\n\u001B[1;32m    853\u001B[0m     database\u001B[38;5;241m=\u001B[39mdatabase, imp_user\u001B[38;5;241m=\u001B[39mimp_user, bookmarks\u001B[38;5;241m=\u001B[39mbookmarks,\n\u001B[1;32m    854\u001B[0m     auth\u001B[38;5;241m=\u001B[39mauth, acquisition_timeout\u001B[38;5;241m=\u001B[39macquisition_timeout,\n\u001B[1;32m    855\u001B[0m     database_callback\u001B[38;5;241m=\u001B[39mdatabase_callback\n\u001B[1;32m    856\u001B[0m )\n\u001B[1;32m    857\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mupdate_connection_pool(database\u001B[38;5;241m=\u001B[39mdatabase)\n\u001B[1;32m    859\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/py311/lib/python3.11/site-packages/neo4j/_sync/io/_pool.py:802\u001B[0m, in \u001B[0;36mNeo4jPool.update_routing_table\u001B[0;34m(self, database, imp_user, bookmarks, auth, acquisition_timeout, database_callback)\u001B[0m\n\u001B[1;32m    800\u001B[0m \u001B[38;5;66;03m# None of the routers have been successful, so just fail\u001B[39;00m\n\u001B[1;32m    801\u001B[0m log\u001B[38;5;241m.\u001B[39merror(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mUnable to retrieve routing information\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m--> 802\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m ServiceUnavailable(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mUnable to retrieve routing information\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[0;31mServiceUnavailable\u001B[0m: Unable to retrieve routing information"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-12T10:07:06.495869Z",
     "start_time": "2024-07-12T10:06:59.667071Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "\n",
    "log(\"Running connected components.\")\n",
    "res = gds.wcc.mutate(G, mutateProperty=\"componentId4\", concurrency=12)\n",
    "log(\"Connected components complete.\")\n",
    "res"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-12 12:06:59.668299\tRunning connected components.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "WCC:   0%|          | 0/100 [00:00<?, ?%/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "bdae4fac48de4a4fae824dc55481fb5d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-12 12:07:06.490751\tConnected components complete.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "mutateMillis                                                             0\n",
       "nodePropertiesWritten                                             29987835\n",
       "componentCount                                                           1\n",
       "componentDistribution    {'min': 29987712, 'p5': 29987839, 'max': 29987...\n",
       "postProcessingMillis                                                   386\n",
       "preProcessingMillis                                                      0\n",
       "computeMillis                                                         6289\n",
       "configuration            {'mutateProperty': 'componentId4', 'jobId': '2...\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-12T10:04:52.972907Z",
     "start_time": "2024-07-12T10:04:52.773586Z"
    }
   },
   "cell_type": "code",
   "source": "gds.graph.list()[\"schema\"][0]",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'graphProperties': {},\n",
       " 'nodes': {'Message': {},\n",
       "  'Post': {},\n",
       "  'Tag': {},\n",
       "  'Comment': {},\n",
       "  'Forum': {},\n",
       "  'Continent': {},\n",
       "  'Company': {},\n",
       "  'Country': {},\n",
       "  'TagClass': {},\n",
       "  'City': {},\n",
       "  'Person': {},\n",
       "  'University': {}},\n",
       " 'relationships': {'POST_HAS_CREATOR': {},\n",
       "  'COMMENT_HAS_TAG': {},\n",
       "  'LIKES_POST': {},\n",
       "  'REPLY_OF_COMMENT': {},\n",
       "  'POST_IS_LOCATED_IN': {},\n",
       "  'WORKS_AT': {},\n",
       "  'CONTAINER_OF': {},\n",
       "  'REPLY_OF_POST': {},\n",
       "  'IS_SUBCLASS_OF': {},\n",
       "  'COMMENT_IS_LOCATED_IN': {},\n",
       "  'HAS_TYPE': {},\n",
       "  'STUDY_AT': {},\n",
       "  'POST_HAS_TAG': {},\n",
       "  'LIKES_COMMENT': {},\n",
       "  'HAS_MEMBER': {},\n",
       "  'ORGANISATION_IS_LOCATED_IN': {},\n",
       "  'IS_PART_OF': {},\n",
       "  'FORUM_HAS_TAG': {},\n",
       "  'KNOWS': {},\n",
       "  'HAS_INTEREST': {},\n",
       "  'PERSON_IS_LOCATED_IN': {},\n",
       "  'HAS_MODERATOR': {},\n",
       "  'COMMENT_HAS_CREATOR': {}}}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-12T10:43:21.116577Z",
     "start_time": "2024-07-12T10:40:45.944821Z"
    }
   },
   "cell_type": "code",
   "source": [
    "log(\"Running kNN.\")\n",
    "res = gds.knn.stats(G, nodeProperties=\"componentId\", topK=3, sudo=True, concurrency=12) # writeRelationshipType=\"SIMILAR\", writeProperty=\"score\", arrowConfiguration={\"batchSize\": 1000}\n",
    "log(\"kNN complete.\")\n",
    "res"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-12 12:40:45.945646\tRunning kNN.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "K-Nearest Neighbours:   0%|          | 0/100 [00:00<?, ?%/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f9b203c149eb4455bd85d957e8616ee7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-12 12:43:21.111768\tkNN complete.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ranIterations                                                             1\n",
       "didConverge                                                            True\n",
       "nodePairsConsidered                                               632992271\n",
       "preProcessingMillis                                                       0\n",
       "computeMillis                                                         93656\n",
       "postProcessingMillis                                                   2868\n",
       "nodesCompared                                                      29987835\n",
       "similarityPairs                                                    89963505\n",
       "similarityDistribution    {'min': 1.0, 'p5': 1.0, 'max': 1.0000076293945...\n",
       "configuration             {'jobId': 'c3b2003c-edf1-49e9-8015-c21a7f7a132...\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-12T12:13:14.004324Z",
     "start_time": "2024-07-12T12:11:24.737631Z"
    }
   },
   "cell_type": "code",
   "source": [
    "log(\"Running kNN.\")\n",
    "res = gds.knn.mutate(G, nodeProperties=\"componentId\", topK=3, sudo=True, concurrency=12, mutateRelationshipType=\"SIMILAR\", mutateProperty=\"score\") # writeRelationshipType=\"SIMILAR\", writeProperty=\"score\", arrowConfiguration={\"batchSize\": 1000}\n",
    "log(\"kNN complete.\")\n",
    "res"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-12 14:11:24.739425\tRunning kNN.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "K-Nearest Neighbours:   0%|          | 0/100 [00:00<?, ?%/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d2e48a09b819404d897dfe00b04bf5a9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-12 14:13:13.999872\tkNN complete.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ranIterations                                                             1\n",
       "nodePairsConsidered                                               633011613\n",
       "didConverge                                                            True\n",
       "preProcessingMillis                                                       1\n",
       "computeMillis                                                         77528\n",
       "mutateMillis                                                          31006\n",
       "postProcessingMillis                                                      0\n",
       "nodesCompared                                                      29987835\n",
       "relationshipsWritten                                               89963505\n",
       "similarityDistribution    {'min': 1.0, 'p5': 1.0, 'max': 1.0000076293945...\n",
       "configuration             {'mutateProperty': 'score', 'jobId': '5438ddb1...\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-12T14:04:35.509758Z",
     "start_time": "2024-07-12T12:40:02.923609Z"
    }
   },
   "cell_type": "code",
   "source": "gds.graph.writeRelationship(G, \"SIMILAR\", \"score\")",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to write data to connection ResolvedIPv4Address(('35.195.103.236', 7687)) (ResolvedIPv4Address(('35.195.103.236', 7687)))\n",
      "Failed to write data to connection IPv4Address(('ad6df740-staging.databases.neo4j.io', 7687)) (ResolvedIPv4Address(('35.195.103.236', 7687)))\n"
     ]
    },
    {
     "ename": "ClientError",
     "evalue": "{code: Neo.ClientError.Procedure.ProcedureCallFailed} {message: Failed to invoke procedure `gds.arrow.write`: Caused by: org.neo4j.kernel.DeadlockDetectedException: ForsetiClient[transactionId=1525, clientId=35] can't acquire ExclusiveLock{owner=ForsetiClient[transactionId=1519, clientId=34]} on RELATIONSHIP(187363187) because holders of that lock are waiting for ForsetiClient[transactionId=1525, clientId=35].\n Wait list:ExclusiveLock[\nClient[1519] waits for [ForsetiClient[transactionId=1525, clientId=35]]]}",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mClientError\u001B[0m                               Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[25], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m gds\u001B[38;5;241m.\u001B[39mgraph\u001B[38;5;241m.\u001B[39mwriteRelationship(G, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mSIMILAR\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mscore\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/gitRoots/graph-data-science-client/graphdatascience/graph/base_graph_proc_runner.py:514\u001B[0m, in \u001B[0;36mBaseGraphProcRunner.writeRelationship\u001B[0;34m(self, G, relationship_type, relationship_property, **config)\u001B[0m\n\u001B[1;32m    506\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_namespace \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m.writeRelationship\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    507\u001B[0m params \u001B[38;5;241m=\u001B[39m CallParameters(\n\u001B[1;32m    508\u001B[0m     graph_name\u001B[38;5;241m=\u001B[39mG\u001B[38;5;241m.\u001B[39mname(),\n\u001B[1;32m    509\u001B[0m     relationship_type\u001B[38;5;241m=\u001B[39mrelationship_type,\n\u001B[1;32m    510\u001B[0m     relationship_property\u001B[38;5;241m=\u001B[39mrelationship_property,\n\u001B[1;32m    511\u001B[0m     config\u001B[38;5;241m=\u001B[39mconfig,\n\u001B[1;32m    512\u001B[0m )\n\u001B[0;32m--> 514\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_query_runner\u001B[38;5;241m.\u001B[39mcall_procedure(  \u001B[38;5;66;03m# type: ignore\u001B[39;00m\n\u001B[1;32m    515\u001B[0m     endpoint\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_namespace,\n\u001B[1;32m    516\u001B[0m     params\u001B[38;5;241m=\u001B[39mparams,\n\u001B[1;32m    517\u001B[0m )\u001B[38;5;241m.\u001B[39msqueeze()\n",
      "File \u001B[0;32m~/gitRoots/graph-data-science-client/graphdatascience/query_runner/aura_db_query_runner.py:54\u001B[0m, in \u001B[0;36mAuraDbQueryRunner.call_procedure\u001B[0;34m(self, endpoint, params, yields, database, logging, custom_error)\u001B[0m\n\u001B[1;32m     51\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_remote_projection(endpoint, params, yields, database, logging)\n\u001B[1;32m     53\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m.write\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m endpoint \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mis_remote_projected_graph(params[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mgraph_name\u001B[39m\u001B[38;5;124m\"\u001B[39m]):\n\u001B[0;32m---> 54\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_remote_write_back(endpoint, params, yields, database, logging, custom_error)\n\u001B[1;32m     56\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_gds_query_runner\u001B[38;5;241m.\u001B[39mcall_procedure(endpoint, params, yields, database, logging, custom_error)\n",
      "File \u001B[0;32m~/gitRoots/graph-data-science-client/graphdatascience/query_runner/aura_db_query_runner.py:144\u001B[0m, in \u001B[0;36mAuraDbQueryRunner._remote_write_back\u001B[0;34m(self, endpoint, params, yields, database, logging, custom_error)\u001B[0m\n\u001B[1;32m    136\u001B[0m db_write_proc_params \u001B[38;5;241m=\u001B[39m {\n\u001B[1;32m    137\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mgraphName\u001B[39m\u001B[38;5;124m\"\u001B[39m: params[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mgraph_name\u001B[39m\u001B[38;5;124m\"\u001B[39m],\n\u001B[1;32m    138\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdatabaseName\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_gds_query_runner\u001B[38;5;241m.\u001B[39mdatabase(),\n\u001B[1;32m    139\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mjobId\u001B[39m\u001B[38;5;124m\"\u001B[39m: job_id,\n\u001B[1;32m    140\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124marrowConfiguration\u001B[39m\u001B[38;5;124m\"\u001B[39m: db_arrow_config,\n\u001B[1;32m    141\u001B[0m }\n\u001B[1;32m    143\u001B[0m write_back_start \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime()\n\u001B[0;32m--> 144\u001B[0m database_write_result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_db_query_runner\u001B[38;5;241m.\u001B[39mcall_procedure(\n\u001B[1;32m    145\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mgds.arrow.write\u001B[39m\u001B[38;5;124m\"\u001B[39m, CallParameters(db_write_proc_params), yields, \u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;28;01mFalse\u001B[39;00m, \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[1;32m    146\u001B[0m )\n\u001B[1;32m    147\u001B[0m write_millis \u001B[38;5;241m=\u001B[39m (time\u001B[38;5;241m.\u001B[39mtime() \u001B[38;5;241m-\u001B[39m write_back_start) \u001B[38;5;241m*\u001B[39m \u001B[38;5;241m1000\u001B[39m\n\u001B[1;32m    148\u001B[0m gds_write_result[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mwriteMillis\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m write_millis\n",
      "File \u001B[0;32m~/gitRoots/graph-data-science-client/graphdatascience/query_runner/neo4j_query_runner.py:152\u001B[0m, in \u001B[0;36mNeo4jQueryRunner.call_procedure\u001B[0;34m(self, endpoint, params, yields, database, logging, custom_error)\u001B[0m\n\u001B[1;32m    150\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrun_cypher_with_logging(query, params, database)\n\u001B[1;32m    151\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 152\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrun_cypher(query, params, database, custom_error)\n",
      "File \u001B[0;32m~/gitRoots/graph-data-science-client/graphdatascience/query_runner/neo4j_query_runner.py:120\u001B[0m, in \u001B[0;36mNeo4jQueryRunner.run_cypher\u001B[0;34m(self, query, params, database, custom_error)\u001B[0m\n\u001B[1;32m    113\u001B[0m \u001B[38;5;66;03m# Though pandas support may be experimental in the `neo4j` package, it should always\u001B[39;00m\n\u001B[1;32m    114\u001B[0m \u001B[38;5;66;03m# be supported in the `graphdatascience` package.\u001B[39;00m\n\u001B[1;32m    115\u001B[0m warnings\u001B[38;5;241m.\u001B[39mfilterwarnings(\n\u001B[1;32m    116\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mignore\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    117\u001B[0m     message\u001B[38;5;241m=\u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m^pandas support is experimental and might be changed or removed in future versions$\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    118\u001B[0m )\n\u001B[0;32m--> 120\u001B[0m df \u001B[38;5;241m=\u001B[39m result\u001B[38;5;241m.\u001B[39mto_df()\n\u001B[1;32m    122\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_NEO4J_DRIVER_VERSION \u001B[38;5;241m<\u001B[39m ServerVersion(\u001B[38;5;241m5\u001B[39m, \u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m0\u001B[39m):\n\u001B[1;32m    123\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_last_bookmarks \u001B[38;5;241m=\u001B[39m [session\u001B[38;5;241m.\u001B[39mlast_bookmark()]\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/py311/lib/python3.11/site-packages/neo4j/_sync/work/result.py:769\u001B[0m, in \u001B[0;36mResult.to_df\u001B[0;34m(self, expand, parse_dates)\u001B[0m\n\u001B[1;32m    766\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mpandas\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mpd\u001B[39;00m  \u001B[38;5;66;03m# type: ignore[import]\u001B[39;00m\n\u001B[1;32m    768\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m expand:\n\u001B[0;32m--> 769\u001B[0m     df \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mDataFrame(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mvalues(), columns\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_keys)\n\u001B[1;32m    770\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    771\u001B[0m     df_keys \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/py311/lib/python3.11/site-packages/neo4j/_sync/work/result.py:619\u001B[0m, in \u001B[0;36mResult.values\u001B[0;34m(self, *keys)\u001B[0m\n\u001B[1;32m    600\u001B[0m \u001B[38;5;129m@NonConcurrentMethodChecker\u001B[39m\u001B[38;5;241m.\u001B[39mnon_concurrent_method\n\u001B[1;32m    601\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mvalues\u001B[39m(\n\u001B[1;32m    602\u001B[0m     \u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39mkeys: _TResultKey\n\u001B[1;32m    603\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m t\u001B[38;5;241m.\u001B[39mList[t\u001B[38;5;241m.\u001B[39mList[t\u001B[38;5;241m.\u001B[39mAny]]:\n\u001B[1;32m    604\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Return the remainder of the result as a list of values lists.\u001B[39;00m\n\u001B[1;32m    605\u001B[0m \n\u001B[1;32m    606\u001B[0m \u001B[38;5;124;03m    :param keys: fields to return for each remaining record. Optionally filtering to include only certain values by index or key.\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    617\u001B[0m \u001B[38;5;124;03m        Can raise :exc:`.ResultConsumedError`.\u001B[39;00m\n\u001B[1;32m    618\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 619\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m [record\u001B[38;5;241m.\u001B[39mvalues(\u001B[38;5;241m*\u001B[39mkeys) \u001B[38;5;28;01mfor\u001B[39;00m record \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m]\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/py311/lib/python3.11/site-packages/neo4j/_sync/work/result.py:619\u001B[0m, in \u001B[0;36m<listcomp>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m    600\u001B[0m \u001B[38;5;129m@NonConcurrentMethodChecker\u001B[39m\u001B[38;5;241m.\u001B[39mnon_concurrent_method\n\u001B[1;32m    601\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mvalues\u001B[39m(\n\u001B[1;32m    602\u001B[0m     \u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39mkeys: _TResultKey\n\u001B[1;32m    603\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m t\u001B[38;5;241m.\u001B[39mList[t\u001B[38;5;241m.\u001B[39mList[t\u001B[38;5;241m.\u001B[39mAny]]:\n\u001B[1;32m    604\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Return the remainder of the result as a list of values lists.\u001B[39;00m\n\u001B[1;32m    605\u001B[0m \n\u001B[1;32m    606\u001B[0m \u001B[38;5;124;03m    :param keys: fields to return for each remaining record. Optionally filtering to include only certain values by index or key.\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    617\u001B[0m \u001B[38;5;124;03m        Can raise :exc:`.ResultConsumedError`.\u001B[39;00m\n\u001B[1;32m    618\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 619\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m [record\u001B[38;5;241m.\u001B[39mvalues(\u001B[38;5;241m*\u001B[39mkeys) \u001B[38;5;28;01mfor\u001B[39;00m record \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m]\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/py311/lib/python3.11/site-packages/neo4j/_sync/work/result.py:270\u001B[0m, in \u001B[0;36mResult.__iter__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    268\u001B[0m     \u001B[38;5;28;01myield\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_record_buffer\u001B[38;5;241m.\u001B[39mpopleft()\n\u001B[1;32m    269\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_streaming:\n\u001B[0;32m--> 270\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_connection\u001B[38;5;241m.\u001B[39mfetch_message()\n\u001B[1;32m    271\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_discarding:\n\u001B[1;32m    272\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_discard()\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/py311/lib/python3.11/site-packages/neo4j/_sync/io/_common.py:178\u001B[0m, in \u001B[0;36mConnectionErrorHandler.__getattr__.<locals>.outer.<locals>.inner\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    176\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21minner\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m    177\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 178\u001B[0m         func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m    179\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m (Neo4jError, ServiceUnavailable, SessionExpired) \u001B[38;5;28;01mas\u001B[39;00m exc:\n\u001B[1;32m    180\u001B[0m         \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m asyncio\u001B[38;5;241m.\u001B[39miscoroutinefunction(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m__on_error)\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/py311/lib/python3.11/site-packages/neo4j/_sync/io/_bolt.py:850\u001B[0m, in \u001B[0;36mBolt.fetch_message\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    846\u001B[0m \u001B[38;5;66;03m# Receive exactly one message\u001B[39;00m\n\u001B[1;32m    847\u001B[0m tag, fields \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minbox\u001B[38;5;241m.\u001B[39mpop(\n\u001B[1;32m    848\u001B[0m     hydration_hooks\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mresponses[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39mhydration_hooks\n\u001B[1;32m    849\u001B[0m )\n\u001B[0;32m--> 850\u001B[0m res \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_process_message(tag, fields)\n\u001B[1;32m    851\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39midle_since \u001B[38;5;241m=\u001B[39m monotonic()\n\u001B[1;32m    852\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m res\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/py311/lib/python3.11/site-packages/neo4j/_sync/io/_bolt5.py:369\u001B[0m, in \u001B[0;36mBolt5x0._process_message\u001B[0;34m(self, tag, fields)\u001B[0m\n\u001B[1;32m    367\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_server_state_manager\u001B[38;5;241m.\u001B[39mstate \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbolt_states\u001B[38;5;241m.\u001B[39mFAILED\n\u001B[1;32m    368\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 369\u001B[0m     response\u001B[38;5;241m.\u001B[39mon_failure(summary_metadata \u001B[38;5;129;01mor\u001B[39;00m {})\n\u001B[1;32m    370\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m (ServiceUnavailable, DatabaseUnavailable):\n\u001B[1;32m    371\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpool:\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/py311/lib/python3.11/site-packages/neo4j/_sync/io/_common.py:245\u001B[0m, in \u001B[0;36mResponse.on_failure\u001B[0;34m(self, metadata)\u001B[0m\n\u001B[1;32m    243\u001B[0m handler \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandlers\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mon_summary\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    244\u001B[0m Util\u001B[38;5;241m.\u001B[39mcallback(handler)\n\u001B[0;32m--> 245\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m Neo4jError\u001B[38;5;241m.\u001B[39mhydrate(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mmetadata)\n",
      "\u001B[0;31mClientError\u001B[0m: {code: Neo.ClientError.Procedure.ProcedureCallFailed} {message: Failed to invoke procedure `gds.arrow.write`: Caused by: org.neo4j.kernel.DeadlockDetectedException: ForsetiClient[transactionId=1525, clientId=35] can't acquire ExclusiveLock{owner=ForsetiClient[transactionId=1519, clientId=34]} on RELATIONSHIP(187363187) because holders of that lock are waiting for ForsetiClient[transactionId=1525, clientId=35].\n Wait list:ExclusiveLock[\nClient[1519] waits for [ForsetiClient[transactionId=1525, clientId=35]]]}"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "log(\"Writing node properties.\")\n",
    "gds.graph.nodeProperties.write(G, node_properties=[\"componentId\"])\n",
    "log(\"Node properties written.\")\n",
    "\n",
    "res = gds.run_cypher(\"\"\"\n",
    "    MATCH (n)       \n",
    "    OPTIONAL MATCH (n)-[r:SIMILAR]->()\n",
    "    WITH n, count(r) as similars\n",
    "    WHERE similars = 0 OR n.componentId is null\n",
    "    RETURN COUNT(n) as interesting\n",
    "\"\"\")\n",
    "\n",
    "result = res[\"interesting\"][0]\n",
    "log(f\"There are {result} nodes with no relationships or no componentId.\")\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Aura API credentials\n",
    "\n",
    "A GDS Session is created and accessed via the Aura API.\n",
    "In order to use the Aura API, we need to have Aura API credentials.\n",
    "For how to create these credentials, see the [Aura documentation](https://neo4j.com/docs/aura/platform/api/authentication/#_creating_credentials).\n",
    "\n",
    "Using these credentials, we can create our `GdsSessions` object, which is the main entry point for managing GDS Sessions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a new session\n",
    "\n",
    "A new session is created by calling `sessions.get_or_create()`.\n",
    "When we want to do this, we must identify a data source.\n",
    "We assume here that an AuraDB instance has been created and is available to access.\n",
    "We need to provide the database Bolt address, username, and password to the `DbmsConnectionInfo` class.\n",
    "\n",
    "We also have to specify the size of the session.\n",
    "There are many possible sizes to choose from.\n",
    "Please refer to the API reference docs or the manual for a full list.\n",
    "\n",
    "Lastly, we need to give our session a name.\n",
    "We will call ours `analysing-people-and-fruits`.\n",
    "If we had already created a session and want to reconnect to it, the same code is used.\n",
    "Doing that will not incur any additional costs, and will be a lot faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from graphdatascience.session import DbmsConnectionInfo, AlgorithmCategory\n",
    "\n",
    "# Identify the AuraDB instance\n",
    "aura_db_address = os.environ[\"AURA_DB_ADDRESS\"]\n",
    "aura_db_user = os.environ[\"AURA_DB_USER\"]\n",
    "aura_db_pw = os.environ[\"AURA_DB_PW\"]\n",
    "\n",
    "# Create a GDS session!\n",
    "memory = sessions.estimate(\n",
    "    node_count=20,\n",
    "    relationship_count=50,\n",
    "    algorithm_categories=[AlgorithmCategory.CENTRALITY, AlgorithmCategory.NODE_EMBEDDING],\n",
    ")\n",
    "gds = sessions.get_or_create(\n",
    "    # we give it a representative name\n",
    "    session_name=\"people-and-fruits\",\n",
    "    memory=memory,\n",
    "    db_connection=DbmsConnectionInfo(aura_db_address, aura_db_user, aura_db_pw),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Listing sessions\n",
    "\n",
    "Now that we have created a session, let's list all our sessions to see what that looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sessions.list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding a dataset\n",
    "\n",
    "We assume that the configured AuraDB instance is empty.\n",
    "We will add our dataset using standard Cypher.\n",
    "\n",
    "In a more realistic scenario, this step is already done, and we would just connect to the existing database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_query = \"\"\"\n",
    "  CREATE\n",
    "    (dan:Person {name: 'Dan',     age: 18, experience: 63, hipster: 0}),\n",
    "    (annie:Person {name: 'Annie', age: 12, experience: 5, hipster: 0}),\n",
    "    (matt:Person {name: 'Matt',   age: 22, experience: 42, hipster: 0}),\n",
    "    (jeff:Person {name: 'Jeff',   age: 51, experience: 12, hipster: 0}),\n",
    "    (brie:Person {name: 'Brie',   age: 31, experience: 6, hipster: 0}),\n",
    "    (elsa:Person {name: 'Elsa',   age: 65, experience: 23, hipster: 1}),\n",
    "    (john:Person {name: 'John',   age: 4, experience: 100, hipster: 0}),\n",
    "    \n",
    "    (apple:Fruit {name: 'Apple',   tropical: 0, sourness: 0.3, sweetness: 0.6}),\n",
    "    (banana:Fruit {name: 'Banana', tropical: 1, sourness: 0.1, sweetness: 0.9}),\n",
    "    (mango:Fruit {name: 'Mango',   tropical: 1, sourness: 0.3, sweetness: 1.0}),\n",
    "    (plum:Fruit {name: 'Plum',     tropical: 0, sourness: 0.5, sweetness: 0.8})\n",
    "  \n",
    "  CREATE\n",
    "    (dan)-[:LIKES]->(apple),\n",
    "    (annie)-[:LIKES]->(banana),\n",
    "    (matt)-[:LIKES]->(mango),\n",
    "    (jeff)-[:LIKES]->(mango),\n",
    "    (brie)-[:LIKES]->(banana),\n",
    "    (elsa)-[:LIKES]->(plum),\n",
    "    (john)-[:LIKES]->(plum),\n",
    "  \n",
    "    (dan)-[:KNOWS]->(annie),\n",
    "    (dan)-[:KNOWS]->(matt),\n",
    "    (annie)-[:KNOWS]->(matt),\n",
    "    (annie)-[:KNOWS]->(jeff),\n",
    "    (annie)-[:KNOWS]->(brie),\n",
    "    (matt)-[:KNOWS]->(brie),\n",
    "    (brie)-[:KNOWS]->(elsa),\n",
    "    (brie)-[:KNOWS]->(jeff),\n",
    "    (john)-[:KNOWS]->(jeff);\n",
    "\"\"\"\n",
    "\n",
    "# making sure the database is actually empty\n",
    "assert gds.run_cypher(\"MATCH (n) RETURN count(n)\").squeeze() == 0, \"Database is not empty!\"\n",
    "\n",
    "# let's now write our graph!\n",
    "gds.run_cypher(data_query)\n",
    "\n",
    "gds.run_cypher(\"MATCH (n) RETURN count(n) AS nodeCount\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Projecting Graphs\n",
    "\n",
    "Now that we have imported a graph to our database, we can project it into our GDS Session.\n",
    "We do that by using the `gds.graph.project()` endpoint.\n",
    "\n",
    "The remote projection query that we are using selects all `Person` nodes and their `LIKES` relationships, and all `Fruit` nodes and their `LIKES` relationships.\n",
    "Additionally, we project node properties for illustrative purposes.\n",
    "We can use these node properties as input to algorithms, although we do not do that in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G, result = gds.graph.project(\n",
    "    \"people-and-fruits\",\n",
    "    \"\"\"\n",
    "    CALL {\n",
    "        MATCH (p1:Person)\n",
    "        OPTIONAL MATCH (p1)-[r:KNOWS]->(p2:Person)\n",
    "        RETURN \n",
    "          p1 AS source, r AS rel, p2 AS target, \n",
    "          p1 {.age, .experience, .hipster } AS sourceNodeProperties, \n",
    "          p2 {.age, .experience, .hipster } AS targetNodeProperties\n",
    "        UNION\n",
    "        MATCH (f:Fruit)\n",
    "        OPTIONAL MATCH (f)<-[r:LIKES]-(p:Person)\n",
    "        RETURN \n",
    "          p AS source, r AS rel, f AS target, \n",
    "          p {.age, .experience, .hipster } AS sourceNodeProperties, \n",
    "          f { .tropical, .sourness, .sweetness } AS targetNodeProperties\n",
    "    }\n",
    "    RETURN gds.graph.project.remote(source, target, {\n",
    "      sourceNodeProperties: sourceNodeProperties,\n",
    "      targetNodeProperties: targetNodeProperties,\n",
    "      sourceNodeLabels: labels(source),\n",
    "      targetNodeLabels: labels(target),\n",
    "      relationshipType: type(rel)\n",
    "    })\n",
    "    \"\"\",\n",
    ")\n",
    "\n",
    "str(G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running Algorithms\n",
    "\n",
    "We can now run algorithms on the projected graph.\n",
    "This is done using the standard GDS Python Client API.\n",
    "There are many other tutorials covering some interesting things we can do at this step, so we will keep it rather brief here.\n",
    "\n",
    "We will simply run PageRank and FastRP on the graph.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Running PageRank ...\")\n",
    "pr_result = gds.pageRank.mutate(G, mutateProperty=\"pagerank\")\n",
    "print(f\"Compute millis: {pr_result['computeMillis']}\")\n",
    "print(f\"Node properties written: {pr_result['nodePropertiesWritten']}\")\n",
    "print(f\"Centrality distribution: {pr_result['centralityDistribution']}\")\n",
    "\n",
    "print(\"Running FastRP ...\")\n",
    "frp_result = gds.fastRP.mutate(\n",
    "    G,\n",
    "    mutateProperty=\"fastRP\",\n",
    "    embeddingDimension=8,\n",
    "    featureProperties=[\"pagerank\"],\n",
    "    propertyRatio=0.2,\n",
    "    nodeSelfInfluence=0.2,\n",
    ")\n",
    "print(f\"Compute millis: {frp_result['computeMillis']}\")\n",
    "# stream back the results\n",
    "gds.graph.nodeProperties.stream(G, [\"pagerank\", \"fastRP\"], separate_property_columns=True, db_node_properties=[\"name\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing back to AuraDB\n",
    "\n",
    "The GDS Session's in-memory graph was projected from data in our specified AuraDB instance.\n",
    "Write back operations will thus persist the data back to the same AuraDB.\n",
    "Let's write back the results of the PageRank and FastRP algorithms to the AuraDB instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if this fails once with some error like \"unable to retrieve routing table\"\n",
    "# then run it again. this is a transient error with a stale server cache.\n",
    "gds.graph.nodeProperties.write(G, [\"pagerank\", \"fastRP\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, we can just use `.write` modes as well.\n",
    "Let's run Louvain in write mode to show:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gds.louvain.write(G, writeProperty=\"louvain\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now use the `gds.run_cypher()` method to query the updated graph.\n",
    "Note that the `run_cypher()` method will run the query on the AuraDB instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gds.run_cypher(\n",
    "    \"\"\"\n",
    "    MATCH (p:Person) \n",
    "    RETURN p.name, p.pagerank AS rank, p.louvain \n",
    "     ORDER BY rank DESC\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deleting the session\n",
    "\n",
    "Now that we have finished our analysis, we can delete the session.\n",
    "The results that we produced were written back to our AuraDB instance, and will not be lost.\n",
    "If we computed additional things that we did not write back, those will be lost.\n",
    "\n",
    "Deleting the session will release all resources associated with it, and stop incurring costs."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [
     "teardown"
    ],
    "ExecuteTime": {
     "end_time": "2024-07-12T15:42:41.161915Z",
     "start_time": "2024-07-12T15:42:39.686574Z"
    }
   },
   "source": "sessions.delete(\"e2e-test-gcp\")",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 34
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-12T15:42:45.320186Z",
     "start_time": "2024-07-12T15:42:43.944340Z"
    }
   },
   "source": [
    "# let's also make sure the deleted session is truly gone:\n",
    "sessions.list()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 35
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "teardown"
    ]
   },
   "outputs": [],
   "source": [
    "# Lastly, let's clean up the database\n",
    "gds.run_cypher(\"MATCH (n:Person|Fruit) DETACH DELETE n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "And we're done!\n",
    "We have created a GDS Session, projected a graph, run some algorithms, written back the results, and deleted the session.\n",
    "This is a simple example, but it shows the main steps of using GDS Sessions."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
